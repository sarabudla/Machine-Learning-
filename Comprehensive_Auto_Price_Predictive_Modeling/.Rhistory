# Setting seed for reproducibility
set.seed(111)
# Reading the data from a CSV file
mushroom_data <- read.csv("/Users/nithyasarabudla/DA5030/mushrooms.csv", na.strings="?")
# Checking the basic structure of the data
str(mushroom_data)
# Checking the dimensions of the data
cat("Dimensions of the dataset", dim(mushroom_data), "\n")
# Checking all the unique values from veil.type
unique(mushroom_data$veil.type)
sum(is.na(mushroom_data$stalk.root))
# Since the veil.type has just 1 distinct value and there are several missing values in stalk.root, dropping both the columns.
cols_to_remove <- c("veil.type", "stalk.root")
mushroom_data <- mushroom_data[, !names(mushroom_data) %in% cols_to_remove]
# Converting the processed data to data frame by converting the columns to factors
mushroom_data <- as.data.frame(lapply(mushroom_data, as.factor))
# Using library caret for splitting
library(caret)
# Setting seed for reproductibility
set.seed(111)
# Splitting the data frame in 70% and 30% ratios without replacement
index <- createDataPartition(mushroom_data$class, p=0.7, list=FALSE)
df_train <- mushroom_data[index,]
df_valid <- mushroom_data[-index,]
# Checking value counts for class in training set
table(df_train$class)
# Checking value counts for class in validation set
table(df_valid$class)
# Checking the dimensions of training and testing sets
cat("Dimensions of the training set:", dim(df_train), "\n")
cat("Dimensions of the testing set:", dim(df_valid), "\n")
library(klaR)
# Building and fitting the Naive Bayes model usin training data
nb_model <- NaiveBayes(class ~ ., data = df_train)
# Validating using the validation data
nb_predictions <- predict(nb_model, newdata = df_valid)
# A function to compute various metrics using confusion matrix and print them
compute_metrics <- function(conf_matrix) {
TP <- conf_matrix[2, 2]
TN <- conf_matrix[1, 1]
FP <- conf_matrix[1, 2]
FN <- conf_matrix[2, 1]
accuracy <- (TP + TN) / sum(conf_matrix)
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
f1_score <- 2 * precision * recall / (precision + recall)
cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
cat("F1 Score:", f1_score, "\n")
}
# Computing the confusion matrix and printing the metrics
confusion_matrix <- table(nb_predictions$class, df_valid$class)
print("NAIVE BAYES MODEL")
compute_metrics(confusion_matrix)
print(confusion_matrix)
# install.packages("C50")
library(C50)
# Building RIPPER model on the training data
ripper_model <- C5.0(df_train[, -which(names(df_train) == "class")], df_train$class)
# Validating using the validation data
ripper_predictions <- predict(ripper_model, newdata = df_valid)
# Computing the confusion matrix and printing the metrics
ripper_confusion_matrix <- table(ripper_predictions, df_valid$class)
print("RIPPER MODEL")
compute_metrics(ripper_confusion_matrix)
print(ripper_confusion_matrix)
# Reading the data from a CSV file
bc_data <- read.csv("/Users/nithyasarabudla/DA5030/Wisonsin_breast_cancer_data.csv")
# Checking the basic structure of data
str(bc_data)
# Checking for the missing values in data.
as.matrix(colSums(is.na(bc_data)))
# Total missing values in data
sum(is.na(bc_data))
cat("Dimensions of the dataset", dim(bc_data), "\n")
# Dropping both the "X" and "id" columns, then converting the label `diagnosis` to factor.
bc_data <- bc_data[, !(names(bc_data) == "X")]
bc_data <- bc_data[, !(names(bc_data) == "id")]
bc_data$diagnosis <- factor(bc_data$diagnosis)
# Printing the head
head(bc_data)
# Setting seed for reproductibility
set.seed(111)
# Splitting the data frame in 75% and 25% ratios without replacement
index <- createDataPartition(bc_data$diagnosis, p=0.75, list=FALSE)
df_train <- bc_data[index,]
df_valid <- bc_data[-index,]
# Checking value counts Dimensions of the dataset
table(df_train$diagnosis)
# Checking value counts of label in validation data
table(df_valid$diagnosis)
# Checking dimensions
cat("Dimensions of the training set:", dim(df_train), "\n")
cat("Dimensions of the testing set:", dim(df_valid), "\n")
# Building and fitting the logistic regression model on training data
logit_model <- glm(diagnosis ~ ., data = df_train, family = binomial)
# Validating it using validation data
logit_predictions <- predict(logit_model, newdata = df_valid, type = "response")
# Classifying the probabilities into classes using 0.5 as threshold.
predicted_classes <- ifelse(as.numeric(logit_predictions) > 0.5, "M", "B")
# Computing the confusion matrix and printing the metrics
logit_confusion_matrix <- table(predicted_classes, df_valid$diagnosis)
print("LOGISTIC REGREESION MODEL")
compute_metrics(logit_confusion_matrix)
print(logit_confusion_matrix)
# Importing the required library for decision tree
library(rpart)
# Building and fitting tree model on training data
tree_model <- rpart(diagnosis ~ ., data = df_train)
# Plotting the tree
plot(tree_model)
text(tree_model, cex = 0.7)
# Validating tree model on validation data
tree_predictions <- predict(tree_model, newdata = df_valid, type = "class")
# Computing the confusion matrix and printing the metrics
tree_confusion_matrix <- table(tree_predictions, df_valid$diagnosis)
print("DECISION TREE MODEL")
compute_metrics(tree_confusion_matrix)
print(tree_confusion_matrix)
# Importing the required library for boosting model
library(C50)
set.seed(111)
# Train the boosting ensemble model with 10 iterations
boost_model <- C5.0(diagnosis ~ ., data = df_train, trials = 10)
# Make predictions on the validation set
boost_predictions <- predict(boost_model, newdata = df_valid)
# Computing the confusion matrix and printing the metrics
boost_confusion_matrix <- table(boost_predictions, df_valid$diagnosis)
print("BOOSTING MODEL")
compute_metrics(boost_confusion_matrix)
print(boost_confusion_matrix)
set.seed(111)
# A function to predict outcome class based on all three models.
predictOutcomeClass <- function(logistic_model, tree_model, boost_model, data) {
# Predict using logistic regression model
logistic_pred <- predict(logistic_model, newdata = data, type = "response")
logistic_pred <- ifelse(logistic_pred > 0.5, "M", "B")
# Predict using decision tree model
tree_pred <- predict(tree_model, newdata = data, type = "class")
# Predict using boosting ensemble model
boost_pred <- predict(boost_model, newdata = data)
# Combine predictions into a data frame
predictions_df <- data.frame(Logistic = logistic_pred, Tree = tree_pred, Boost = boost_pred)
# Use row-wise majority vote to determine final prediction
final_prediction <- apply(predictions_df, 1, function(x) {
tab <- table(x)
as.character(names(tab)[which.max(tab)])
})
return(final_prediction)
}
individual <- data.frame(
radius_mean = 14.5,
texture_mean = 17.0,
perimeter_mean = 87.5,
area_mean = 561.3,
smoothness_mean = 0.098,
compactness_mean = 0.105,
concavity_mean = 0.085,
concave.points_mean = 0.050,
symmetry_mean = 0.180,
fractal_dimension_mean = 0.065,
radius_se = 0.351,
texture_se = 1.015,
perimeter_se = 2.457,
area_se = 26.15,
smoothness_se = 0.005,
compactness_se = 0.022,
concavity_se = 0.036,
concave.points_se = 0.013,
symmetry_se = 0.030,
fractal_dimension_se = 0.005,
radius_worst = 16.5,
texture_worst = 25.3,
perimeter_worst = 114.8,
area_worst = 733.5,
smoothness_worst = 0.155,
compactness_worst = 0.220,
concavity_worst = NA,  # missing value
concave.points_worst = NA,  # missing value
symmetry_worst = 0.360,
fractal_dimension_worst = 0.110
)
# Impute missing values with median
individual$concavity_worst <- median(df_train$concavity_worst, na.rm = TRUE)
individual$concave.points_worst <- median(df_train$concave.points_worst, na.rm = TRUE)
# Predict the diagnosis using the ensemble model
prediction <- predictOutcomeClass(logit_model, tree_model, boost_model, individual)
# Print the prediction
cat("Prediction:", prediction, "\n")
# Import required library for random forest model
library(randomForest)
# Train the Random Forest model on training data
rf_model <- randomForest(diagnosis ~ ., data = df_train, ntree = 100)
# Make predictions on the validation set
rf_predictions <- predict(rf_model, newdata = df_valid)
# Calculate accuracy for Random Forest
rf_accuracy <- mean(rf_predictions == df_valid$diagnosis)
cat("Random Forest Accuracy:", rf_accuracy, "\n")
# Make predictions using the boosting ensemble model
boost_predictions <- predict(boost_model, newdata = df_valid)
# Calculate accuracy for Boosting Ensemble
boost_accuracy <- mean(boost_predictions == df_valid$diagnosis)
cat("Boosting Ensemble Accuracy:", boost_accuracy, "\n")
# Importing the data from downloaded data, where NAs are represented by "?" character.
cars.df <- read.csv("/Users/nithyasarabudla/DA5030/automobile/imports-85.data", na.strings = "?")
# As the columns names are not provided in the data, those are manually set.
colnames(cars.df) <- c(
"symboling", "normalized_losses", "make", "fuel_type", "aspiration",
"num_of_doors", "body_style", "drive_wheels", "engine_location",
"wheel_base", "length", "width", "height", "curb_weight",
"engine_type", "num_of_cylinders", "engine_size", "fuel_system",
"bore", "stroke", "compression_ratio", "horsepower", "peak_rpm",
"city_mpg", "highway_mpg", "price"
)
# Checking the basic structure of data
str(cars.df)
# Required categorical columns
categorical_columns <- c("num_of_doors", "num_of_cylinders", "engine_location")
# All numeric type columns
numeric_columns <- sapply(cars.df, is.numeric)
# All integer type columns
integer_columns <- sapply(cars.df, is.integer)
# merging integer type and numeric type into one.
num_int_columns <- names(cars.df)[numeric_columns | integer_columns]
# Finally, merging all the required columns
selected_columns <- c(categorical_columns, num_int_columns)
# Filtering the required columns.
cars.df <- cars.df[, selected_columns]
as.matrix(sapply(cars.df, FUN = function (x) sum(is.na(x))))
# For numeric/integer columns, impute the missing values with the column's median value.
for (col in num_int_columns) {
cars.df[[col]] <- ifelse(is.na(cars.df[[col]]), median(cars.df[[col]], na.rm = TRUE), cars.df[[col]])
}
# For the categorical data, the missing value is present in "num_of_doors" column, it is better to impute them with most frequent value.
mode_num_of_doors <- names(which.max(table(cars.df$num_of_doors)))
cars.df$num_of_doors[is.na(cars.df$num_of_doors)] <- mode_num_of_doors
cat("Total missing values after imputation:", sum(is.na(cars.df)), "\n")
# Encode the written numbers with actual numeric numbers.
door_mapping <- c("two" = 2, "four" = 4)
cylinder_mapping <- c("two" = 2, "three" = 3, "four" = 4, "five" = 5, "six" = 6, "eight" = 8, "twelve" = 12)
cars.df$num_of_doors <- as.integer(door_mapping[cars.df$num_of_doors])
cars.df$num_of_cylinders <- as.integer(cylinder_mapping[cars.df$num_of_cylinders])
# Factorize the engine location column.
cars.df$engine_location <- as.integer(factor(cars.df$engine_location, levels = c("front", "rear")))
# Checking the structure and types of data
str(cars.df)
# Duplicate cars.df into cars.no.df
cars.no.df <- cars.df
# Function to detect outliers using IQR method, ignoring specified columns
detect_outliers_ignore <- function(x) {
q1 <- quantile(x, 0.25)
q3 <- quantile(x, 0.75)
# Compute the inter quartile range
iqr <- q3 - q1
lower_bound <- q1 - 1.5 * iqr
upper_bound <- q3 + 1.5 * iqr
outliers <- x[x < lower_bound | x > upper_bound]
return(list(count = length(outliers), outliers = outliers))
}
# Iterate over each column and remove outliers from cars.no.df
for (col in names(cars.no.df)) {
# If the column is categorical, ignore it.
if (!(col %in% categorical_columns)) {
outliers_info <- detect_outliers_ignore(cars.no.df[[col]])
cat("Outliers in", col, ":", outliers_info$count, "\n")
# Remove the outlier rows from cars.no.df
cars.no.df <- cars.no.df[!cars.no.df[[col]] %in% outliers_info$outliers, ]
}
}
cat("Number of Unique values in each column: \n")
for (col in names(cars.no.df)) {
cat(col, ":", length(unique(cars.no.df[, col])), "\n")
}
# Dropping the engine location from cars.no.df
cars.no.df$engine_location <- NULL
# Importing the required packages for pairs.panels
# install.packages("psych")
library(psych)
# Plot the cars.no.df using pairs.panels
pairs.panels(cars.no.df)
# Build a linear regression model
model <- lm(price ~ ., data = cars.no.df)
summary(model)
# Importing required library for computing skewness
library(e1071)
# Identify skewed columns
skewed_columns <- names(Filter(function(x) abs(skewness(x, na.rm = TRUE)) > 0.5, cars.no.df))
# Apply log transformation to skewed columns
cars.tx <- cars.no.df
cars.tx[skewed_columns] <- lapply(cars.tx[skewed_columns], function(x) log(x + 1))
# Calculate correlations
correlations <- cor(cars.no.df)
# Correlation with the response variable (price)
price_correlations <- correlations["price", ]
print(price_correlations)
library(corrplot)
corrplot(correlations, method="number", number.cex=0.4, tl.cex=0.8)
# Set seed for reproductibility
set.seed(111)
# Split cars.df
index <- createDataPartition(cars.df$price, p = 0.7, list = FALSE)
cars.training <- cars.df[index, ]
cars.testing <- cars.df[-index, ]
# Split cars.no.df
index <- createDataPartition(cars.no.df$price, p = 0.7, list = FALSE)
cars.no.training <- cars.no.df[index, ]
cars.no.testing <- cars.no.df[-index, ]
# Split cars.tx
index <- createDataPartition(cars.tx$price, p = 0.7, list = FALSE)
cars.tx.training <- cars.tx[index, ]
cars.tx.testing <- cars.tx[-index, ]
# Building and Fitting multiple regression models on training datasets
# For cars.training
model_training <- lm(price ~ ., data = cars.training)
final_model_training <- step(model_training, direction = "backward")
# For cars.no.training
model_no_training <- lm(price ~ ., data = cars.no.training)
final_model_no_training <- step(model_no_training, direction = "backward")
# For cars.tx.training
model_tx_training <- lm(price ~ ., data = cars.tx.training)
final_model_tx_training <- step(model_tx_training, direction = "backward")
library(rpart)
# Build a regression tree model for cars.training
tree_model_training <- rpart(price ~ ., data = cars.training, method = "anova")
# Build a regression tree model for cars.no.training
tree_model_no_training <- rpart(price ~ ., data = cars.no.training, method = "anova")
# Build a regression tree model for cars.tx.training
tree_model_tx_training <- rpart(price ~ ., data = cars.tx.training, method = "anova")
# Define a function to calculate RMSE
rmse <- function(predicted, actual) {
sqrt(mean((predicted - actual)^2))
}
# Define a function to extract adjusted R2 score
adj_r_squared <- function(model, data) {
1 - (1 - summary(model)$adj.r.squared) * ((nrow(data) - 1) / (nrow(data) - length(model$coefficients) - 1))
}
# Calculate RMSE for each model using their testing datasets
results <- data.frame(
Model = c("Multiple Regression (cars.training)", "Multiple Regression (cars.no.training)", "Multiple Regression (cars.tx.training)",
"Regression Tree (cars.training)", "Regression Tree (cars.no.training)", "Regression Tree (cars.tx.training)"),
Adjusted_R_Squared = c(
adj_r_squared(final_model_training, cars.testing),
adj_r_squared(final_model_no_training, cars.no.testing),
adj_r_squared(final_model_tx_training, cars.tx.testing),
adj_r_squared(tree_model_training, cars.testing),
adj_r_squared(tree_model_no_training, cars.no.testing),
adj_r_squared(tree_model_tx_training, cars.tx.testing)
),
RMSE = c(
rmse(predict(final_model_training, newdata = cars.testing), cars.testing$price),
rmse(predict(final_model_no_training, newdata = cars.no.testing), cars.no.testing$price),
rmse(predict(final_model_tx_training, newdata = cars.tx.testing), cars.tx.testing$price),
rmse(predict(tree_model_training, newdata = cars.testing), cars.testing$price),
rmse(predict(tree_model_no_training, newdata = cars.no.testing), cars.no.testing$price),
rmse(predict(tree_model_tx_training, newdata = cars.tx.testing), cars.tx.testing$price)
)
)
# Print the results
print(results)
# For Multiple Regression models
coef_training <- coef(model_training)
coef_no_training <- coef(model_no_training)
coef_tx_training <- coef(model_tx_training)
# Extract coefficients for highway-mpg and city-mpg
coef_highway_mpg_training <- coef_training["highway_mpg"]
coef_highway_mpg_no_training <- coef_no_training["highway_mpg"]
coef_highway_mpg_tx_training <- coef_tx_training["highway_mpg"]
coef_city_mpg_training <- coef_training["city_mpg"]
coef_city_mpg_no_training <- coef_no_training["city_mpg"]
coef_city_mpg_tx_training <- coef_tx_training["city_mpg"]
# Interpretation
cat("Multiple Regression (cars.training):\n")
cat("One unit change in highway-mpg leads to a change of", coef_highway_mpg_training, "in price.\n")
cat("One unit change in city-mpg leads to a change of", coef_city_mpg_training, "in price.\n\n")
cat("Multiple Regression (cars.no.training):\n")
cat("One unit change in highway-mpg leads to a change of", coef_highway_mpg_no_training, "in price.\n")
cat("One unit change in city-mpg leads to a change of", coef_city_mpg_no_training, "in price.\n\n")
cat("Multiple Regression (cars.tx.training):\n")
cat("One unit change in highway-mpg leads to a change of", coef_highway_mpg_tx_training, "in price.\n")
cat("One unit change in city-mpg leads to a change of", coef_city_mpg_tx_training, "in price.\n\n")
calculate_prediction_interval <- function(model, data) {
# Predicted values
predictions <- predict(model, newdata = data, interval = "prediction" ,level = 0.95)
# Prediction interval
prediction_interval <- data.frame(
Lower = predictions[, "lwr"],
Upper = predictions[, "upr"]
)
return(prediction_interval)
}
prediction_interval_training <- calculate_prediction_interval(final_model_training, cars.training)
prediction_interval_no_training <- calculate_prediction_interval(final_model_no_training, cars.no.training)
prediction_interval_tx_training <- calculate_prediction_interval(final_model_tx_training, cars.tx.training)
# Print the prediction intervals
cat("95% Prediction Interval for Multiple Regression (cars.training):\n")
print(head(prediction_interval_training))
cat("\n95% Prediction Interval for Multiple Regression (cars.no.training):\n")
print(head(prediction_interval_no_training))
cat("\n95% Prediction Interval for Multiple Regression (cars.tx.training):\n")
print(head(prediction_interval_tx_training))
